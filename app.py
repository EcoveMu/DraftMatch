
import streamlit as st
import os, tempfile, re, io
import fitz  # PyMuPDF
import docx, difflib
from pathlib import Path
import pandas as pd
from collections import defaultdict

from text_extraction import extract_text_from_word, extract_text_from_pdf_with_page_info
from comparison_algorithm import compare_pdf_first
from custom_ai import CustomAI
from qwen_ocr import QwenOCR

st.set_page_config(page_title="æœŸåˆŠæ¯”å°ç³»çµ±", page_icon="ğŸ“Š", layout="wide", initial_sidebar_state="expanded")
st.markdown('<link rel="stylesheet" href="custom.css">', unsafe_allow_html=True)
st.markdown('<h1 class="main-header">æœŸåˆŠæ¯”å°ç³»çµ±</h1>', unsafe_allow_html=True)
st.markdown('æœ¬ç³»çµ±ç”¨æ–¼æ¯”å°åŸå§‹Wordæ–‡ä»¶èˆ‡ç¾ç·¨å¾ŒPDFæ–‡ä»¶çš„å…§å®¹å·®ç•°ï¼Œå¹«åŠ©æ ¡å°äººå“¡å¿«é€Ÿæ‰¾å‡ºä¸ä¸€è‡´ä¹‹è™•ã€‚')

# ------------- Session Defaults -----------------
DEFAULTS = dict(
    comparison_mode="hybrid",
    similarity_threshold=0.5,
    use_ocr=False,
    ocr_engine="qwen_builtin",
    ocr_api_key="",
    use_ai=False,
    ai_provider="deepseek_builtin",
    ai_api_key="",
    ignore_whitespace=True,
    ignore_punctuation=True,
    ignore_case=True,
    ignore_linebreaks=True,
    selected_pages=None,
    total_pages=None,
)
for k,v in DEFAULTS.items():
    st.session_state.setdefault(k,v)

# ------------- Side Bar -----------------
with st.sidebar:
    st.header("âš™ï¸ æ¯”å°è¨­å®š")

    # ---- æ¯”å°æ¨¡å¼ ----
    mode_labels = ["æ··åˆæ¯”å°ï¼ˆHybridï¼‰","ç²¾ç¢ºæ¯”å°ï¼ˆExactï¼‰","èªæ„æ¯”å°ï¼ˆSemanticï¼‰","AI æ¯”å°"]
    mode_map = {
        "æ··åˆæ¯”å°ï¼ˆHybridï¼‰":"hybrid",
        "ç²¾ç¢ºæ¯”å°ï¼ˆExactï¼‰":"exact",
        "èªæ„æ¯”å°ï¼ˆSemanticï¼‰":"semantic",
        "AI æ¯”å°":"ai",
    }
    current_label = next(k for k,v in mode_map.items() if v == st.session_state.comparison_mode)
    selected_label = st.radio("æ¯”å°æ¨¡å¼", mode_labels, index=mode_labels.index(current_label))
    st.session_state.comparison_mode = mode_map[selected_label]

    st.session_state.similarity_threshold = st.slider("ç›¸ä¼¼åº¦é–¾å€¼", 0.0, 1.0, st.session_state.similarity_threshold, 0.05)

    st.divider(); st.subheader("ğŸ” OCR è¨­å®š")
    st.session_state.use_ocr = st.checkbox("å•Ÿç”¨ OCR", value=st.session_state.use_ocr)
    if st.session_state.use_ocr:
        ocr_choice = st.radio("OCR å¼•æ“", ["Qwenï¼ˆå…§å»ºï¼‰","EasyOCRï¼ˆå…§å»ºï¼‰","Tesseractï¼ˆå…§å»ºï¼‰","è‡ªå®šç¾© OCR API"], horizontal=True)
        ocr_map = {
            "Qwenï¼ˆå…§å»ºï¼‰":"qwen_builtin",
            "EasyOCRï¼ˆå…§å»ºï¼‰":"easyocr",
            "Tesseractï¼ˆå…§å»ºï¼‰":"tesseract",
            "è‡ªå®šç¾© OCR API":"ocr_custom"
        }
        st.session_state.ocr_engine = ocr_map[ocr_choice]
        if st.session_state.ocr_engine in {"ocr_custom","qwen_api"}:
            st.session_state.ocr_api_key = st.text_input("OCR API Key", type="password", value=st.session_state.ocr_api_key)

    st.divider(); st.subheader("ğŸ¤– ç”Ÿæˆå¼ AI è¨­å®š")
    st.session_state.use_ai = st.checkbox("ä½¿ç”¨ç”Ÿæˆå¼ AI", value=st.session_state.use_ai)
    if st.session_state.use_ai:
        ai_choice = st.selectbox("AI ä¾†æº / æ¨¡å‹", ["DeepSeekï¼ˆå…§å»ºï¼‰","Qwen2.5ï¼ˆå…§å»ºï¼‰","OpenAI","Anthropic","è‡ªå®šç¾© AI API"],
                                 index=["deepseek_builtin","qwen_builtin","openai","anthropic","ai_custom"].index(st.session_state.ai_provider))
        st.session_state.ai_provider = {
            "DeepSeekï¼ˆå…§å»ºï¼‰":"deepseek_builtin","Qwen2.5ï¼ˆå…§å»ºï¼‰":"qwen_builtin",
            "OpenAI":"openai","Anthropic":"anthropic","è‡ªå®šç¾© AI API":"ai_custom"
        }[ai_choice]
        if st.session_state.ai_provider in {"openai","anthropic","ai_custom"}:
            st.session_state.ai_api_key = st.text_input("AI API Key", type="password", value=st.session_state.ai_api_key)

    st.divider(); st.subheader("ğŸ§¹ å¿½ç•¥è¦å‰‡")
    st.session_state.ignore_whitespace = st.checkbox("å¿½ç•¥ç©ºæ ¼", value=st.session_state.ignore_whitespace)
    st.session_state.ignore_punctuation = st.checkbox("å¿½ç•¥æ¨™é»ç¬¦è™Ÿ", value=st.session_state.ignore_punctuation)
    st.session_state.ignore_case = st.checkbox("å¿½ç•¥å¤§å°å¯«", value=st.session_state.ignore_case)
    st.session_state.ignore_linebreaks = st.checkbox("å¿½ç•¥æ–·è¡Œ", value=st.session_state.ignore_linebreaks)

    st.divider(); st.subheader("â„¹ï¸ ç³»çµ±è³‡è¨Š")
    st.info("ç³»çµ±ä¸€æ¬¡æœ€å¤šæ¯”å° 20 é  PDFï¼Œå¯å¤šæ¬¡é¸æ“‡é é¢é€²è¡Œé€æ‰¹æ¯”å°ã€‚")

# ------------- Upload Section -----------------
st.header("ğŸ“ æ–‡ä»¶ä¸Šå‚³")
col1,col2 = st.columns(2)
with col1:
    st.subheader("åŸå§‹Wordæ–‡ä»¶")
    word_file = st.file_uploader("ä¸Šå‚³åŸå§‹ Word æ–‡ç¨¿", type=["docx"], key="word_uploader")
    if word_file: st.success(f"å·²ä¸Šå‚³: {word_file.name}")
with col2:
    st.subheader("ç¾ç·¨å¾ŒPDFæ–‡ä»¶")
    pdf_file = st.file_uploader("ä¸Šå‚³ç¾ç·¨å¾Œ PDF æ–‡ä»¶", type=["pdf"], key="pdf_uploader")
    if pdf_file: st.success(f"å·²ä¸Šå‚³: {pdf_file.name}")

MAX_PAGES = 20
def get_pdf_page_count(uploaded):
    pos=uploaded.tell(); uploaded.seek(0); count=len(fitz.open("pdf", uploaded.read())); uploaded.seek(pos); return count


def select_pdf_pages(pdf_file):
    if "selected_pages" not in st.session_state or st.session_state.selected_pages is None:
        total = get_pdf_page_count(pdf_file)
        st.session_state.total_pages = total
        if total > MAX_PAGES:
            st.warning(f"PDF å…± {total} é ï¼Œç³»çµ±ä¸€æ¬¡æœ€å¤šæ¯”å° {MAX_PAGES} é ï¼Œè«‹é¸æ“‡éœ€æ¯”å°é é¢ã€‚")
            mode = st.radio("é é¢é¸æ“‡æ–¹å¼", ["é€£çºŒå€é–“","æŒ‡å®šé ç¢¼"])
            if mode == "é€£çºŒå€é–“":
                s, e = st.columns(2)
                start = s.number_input("èµ·å§‹é ", 1, total, 1, 1)
                end = e.number_input("çµæŸé ", start, min(start + MAX_PAGES - 1, total), start + MAX_PAGES - 1, 1)
                pages = list(range(int(start), int(end) + 1))
            else:
                pages = st.multiselect("é¸æ“‡é ç¢¼", list(range(1, total + 1)))

            if st.button("âœ… ç¢ºå®šé é¢") and pages and 1 <= len(pages) <= MAX_PAGES:
                st.session_state.selected_pages = sorted(set(pages))
                st.success(f"å·²é¸æ“‡é é¢: {st.session_state.selected_pages}")

    if st.session_state.selected_pages:
        st.info(f"å°‡æ¯”å°é é¢: {st.session_state.selected_pages}")
def build_sub_pdf(uploaded, pages):
    pos=uploaded.tell(); uploaded.seek(0); data=uploaded.read(); uploaded.seek(pos)
    src=fitz.open(stream=data, filetype="pdf")
    new=fitz.open()
    for p in pages:
        if 1<=p<=src.page_count:
            new.insert_pdf(src, from_page=p-1, to_page=p-1)
    buf=io.BytesIO(new.tobytes()); buf.seek(0); return buf

def pdf_page_image(pdf_bytes, page, zoom=1.0):
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        pix = doc.load_page(page-1).get_pixmap(matrix=fitz.Matrix(zoom,zoom))
        return pix.tobytes("png")

# Page selection UI
if pdf_file: select_pdf_pages(pdf_file)

# ------------- Comparison -----------------
st.markdown("---")
if st.button("ğŸš€ é–‹å§‹æ¯”å°", use_container_width=True):
    if not word_file or not pdf_file:
        st.error("è«‹åŒæ™‚ä¸Šå‚³ Word èˆ‡ PDF æ–‡ä»¶")
        st.stop()
    # Prepare PDF bytes
    total_pages = get_pdf_page_count(pdf_file)
    if total_pages>MAX_PAGES and not st.session_state.selected_pages:
        st.error("è«‹å…ˆé¸æ“‡è¦æ¯”å°çš„ PDF é é¢")
        st.stop()
    pages = st.session_state.selected_pages if st.session_state.selected_pages else list(range(1,total_pages+1))
    sub_pdf = build_sub_pdf(pdf_file, pages) if st.session_state.selected_pages else io.BytesIO(pdf_file.read())
    sub_pdf.seek(0)
    # Extract text
    word_data = extract_text_from_word(word_file)
    pdf_paragraphs = extract_text_from_pdf_with_page_info(sub_pdf)
    pdf_data = {"paragraphs": pdf_paragraphs, "tables":[]}
    # AI / OCR instance (stub)
    ai_instance = CustomAI() if st.session_state.use_ai else None
    # Compare
    st.info("æ¯”å°ä¸­ï¼Œè«‹ç¨å€™...")
    res = compare_pdf_first(
        word_data, pdf_data,
        comparison_mode=st.session_state.comparison_mode,
        similarity_threshold=st.session_state.similarity_threshold,
        ignore_options=dict(
            ignore_space=st.session_state.ignore_whitespace,
            ignore_punctuation=st.session_state.ignore_punctuation,
            ignore_case=st.session_state.ignore_case,
            ignore_newline=st.session_state.ignore_linebreaks
        ),
        ai_instance=ai_instance
    )
    st.success(f"å®Œæˆï¼åŒ¹é… {res['statistics']['matched']} æ®µ / PDF æ®µ {res['statistics']['total_pdf']}")

    # Group by page
    page_matches = defaultdict(list)
    for m in res['matches']:
        page_matches[m['pdf_page']].append(m)

    pdf_bytes = sub_pdf.getvalue()
    for p in pages:
        st.subheader(f"ğŸ“„ PDF é  {p}")
        st.image(pdf_page_image(pdf_bytes,p,0.8), use_column_width=True)
        if p in page_matches:
            df = pd.DataFrame([{"Wordæ®µ":m['word_index'],"ç›¸ä¼¼åº¦":f"{m['similarity']:.2f}"} for m in page_matches[p]])
            st.dataframe(df, use_container_width=True)
            for m in page_matches[p]:
                with st.expander(f"Word æ®µ {m['word_index']} (ç›¸ä¼¼åº¦ {m['similarity']:.2f})"):
                    st.markdown("**Wordï¼š**")
                    st.write(m['word_text'])
                    st.markdown("**PDF ç‰‡æ®µï¼š**")
                    st.write(m['pdf_text'])
                    st.markdown("**å·®ç•°ï¼š**", unsafe_allow_html=True)
                    st.markdown(m['diff_html'], unsafe_allow_html=True)
        else:
            st.info("æ­¤é ç„¡åŒ¹é…æ®µè½")

    if st.button("ğŸ”„ é‡æ–°é¸æ“‡ PDF é é¢"):
        st.session_state.selected_pages = None
        st.experimental_rerun()